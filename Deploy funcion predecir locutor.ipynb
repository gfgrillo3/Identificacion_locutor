{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credenciales de acceso al deploy\n",
    "\n",
    "wml_credentials = {\n",
    "    \"apikey\":\"API_KEY_VALUE\",\n",
    "    \"url\":\"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion a  deployar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deployable_callable():\n",
    "    \"\"\"\n",
    "    Función de python deployable que predice la persona del audio e identifica si es el locutor o un impostor\n",
    "    \"\"\"\n",
    "    \n",
    "    #Primero hacemos imports y seteamos configuracion inicial\n",
    "    \n",
    "    import json\n",
    "    from google.cloud import storage\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    from botocore.client import Config\n",
    "    import ibm_boto3\n",
    "    import pickle\n",
    "    from io import BytesIO\n",
    "\n",
    "    import librosa\n",
    "    import numpy as np\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ibm_cos_client = ibm_boto3.client(service_name='s3',\n",
    "        ibm_api_key_id='IBM_API_KEY',\n",
    "        ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "        config=Config(signature_version='oauth'),\n",
    "        endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    \n",
    "    \n",
    "    def get_blob_to_predict_and_bucket(filename):\n",
    "        \"\"\"\n",
    "            Funcion que recibe como parámetro el nombre del audio que hay que predecir, y retorna el blob del mismo\n",
    "        \"\"\"\n",
    "    \n",
    "        #Definimos las credenciales\n",
    "        credentials = {\n",
    "        \"type\": \"service_account\",\n",
    "        \"project_id\": \"cuidartech-7e54f\",\n",
    "        \"private_key_id\": \"PRIVATE_KEY_ID\",\n",
    "        \"private_key\": \"PRIVATE_KEY\",\n",
    "        \"client_email\": \"firebase-adminsdk-8qlnh@cuidartech-7e54f.iam.gserviceaccount.com\",\n",
    "        \"client_id\": \"108378739182204427784\",\n",
    "        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-8qlnh%40cuidartech-7e54f.iam.gserviceaccount.com\"\n",
    "        }\n",
    "\n",
    "\n",
    "        #Cargamos las credenciales como un json, y nos conectamos al cliente del storage de Firebase\n",
    "        json_credentials = json.loads(json.dumps(credentials))\n",
    "\n",
    "        credentials = service_account.Credentials.from_service_account_info(json_credentials)\n",
    "\n",
    "        storage_client = storage.Client(credentials=credentials)\n",
    "\n",
    "\n",
    "        #Creamos la instancia del bucket en donde tenemos los archivos y luego obtenemos el blob solicitado\n",
    "\n",
    "        bucket = storage_client.get_bucket(\"cuidartech-7e54f.appspot.com\")\n",
    "\n",
    "        blob = list(bucket.list_blobs(prefix=filename))[0]\n",
    "\n",
    "        return blob, bucket\n",
    "\n",
    "\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################    \n",
    "    \n",
    "    \n",
    "    def load_model_from_user(username, boto3_client):\n",
    "        \"\"\"\n",
    "            Función que carga el modelo entrenado de un determinado usuario\n",
    "        \"\"\"\n",
    "\n",
    "        username = username.replace(\".\", \"_\")\n",
    "\n",
    "        model_filename = str.upper(username)+\".pickle\"\n",
    "\n",
    "        streaming_body_1 = ibm_cos_client.get_object(Bucket='pruebasgian-donotdelete-pr-3aeebt0ewfpjpi', \n",
    "                                                                              Key=model_filename)['Body']\n",
    "\n",
    "        model = pickle.load(BytesIO(streaming_body_1.read()))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################    \n",
    "        \n",
    "    \n",
    "    def load_MFCC_archivo(archivoVoz, sr=16000, n_mfcc=16, n_fft=512, hop_length=256):\n",
    "        \"\"\"\n",
    "        Función que procesa un archivo para obtener los coeficientes utilizados en la prediccion\n",
    "        Carga de los coeficientes Cepstrum en la escal Mel de un archivo utilizando la librería librosa.\n",
    "        Carga de los coeficientes Cepstrum delta obteniendo información temporal y fonética.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Params:\n",
    "\n",
    "        archivoVoz = archivo a procesar\n",
    "        sr = Sampling Rate del archivo (en Hz)\n",
    "        n_mfcc = cantidad de coeficientes cepstrales a extraer\n",
    "        n_fft = tamaño de la ventana de la transformada de Fourier\n",
    "        hop_length = tamaño del salto para el procesamiento en frames\n",
    "\n",
    "\n",
    "\n",
    "        Para mas información:\n",
    "\n",
    "        MFCC = https://es.wikipedia.org/wiki/MFCC\n",
    "\n",
    "        Librosa MFCC = https://librosa.org/doc/main/generated/librosa.feature.mfcc.html\n",
    "        \"\"\"\n",
    "\n",
    "        y,sr=librosa.load(archivoVoz, sr=sr)\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=n_mfcc, dct_type=2, norm='ortho',\n",
    "                                    hop_length=hop_length, n_fft=n_fft) \n",
    "\n",
    "\n",
    "        #Actualmente en el array tengo n filas x m columnas, donde n es la cantidad de MFCC y m la cantidad de frames\n",
    "        #Traspongo la matriz para quedarme con los features de un determinado frame, es decir n cantidad de MFCC\n",
    "        #columnas x m cantidad de frames filas\n",
    "        mfcc = np.transpose(mfcc)\n",
    "\n",
    "\n",
    "        #Para agregar información temporal y fonética (velocidad, aceleración, entre otras) a los coeficientes\n",
    "        #agrego los delta de cada feature y los concateno al array en formato de columnas\n",
    "        mfcc = np.append(mfcc, librosa.feature.delta(mfcc), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "        return mfcc\n",
    "    \n",
    "        \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################           \n",
    "    \n",
    "    \n",
    "    def make_predictions(model, mfccs):\n",
    "        \"\"\"\n",
    "            Función que utiliza un modelo entrenado y predice utilizando los mfcc de todos los frames de un audio.\n",
    "            Se realiza una predicción para cada frame\n",
    "        \"\"\"\n",
    "\n",
    "        return model.predict(mfccs)\n",
    "    \n",
    "       \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################     \n",
    "    \n",
    "    \n",
    "    def load_names_of_trained_model_from_user(username, boto3_client):\n",
    "        \"\"\"\n",
    "            Función que carga los nombres de las personas del modelo entrenado de un determinado usuario\n",
    "        \"\"\"\n",
    "\n",
    "        username = username.replace(\".\", \"_\")\n",
    "\n",
    "        filename = str.upper(username)+\"_NAMES.pickle\"\n",
    "\n",
    "        streaming_body_1 = ibm_cos_client.get_object(Bucket='pruebasgian-donotdelete-pr-3aeebt0ewfpjpi', \n",
    "                                                                              Key=filename)['Body']\n",
    "\n",
    "        names = pickle.load(BytesIO(streaming_body_1.read()))\n",
    "\n",
    "        return names\n",
    "        \n",
    "        \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################    \n",
    "    \n",
    "    \n",
    "    def prepare_features_to_validate_prediction(predictions, names):\n",
    "        \"\"\"\n",
    "        Función que recibe las predicciones y los nombres de las personas que se entrenaron en el modelo.\n",
    "        Devuelve el nombre de la persona predicha, el porcentaje asignado de frames sobre el total del audio, \n",
    "        y el desvío de frames asignados a la primera y segunda persona.\n",
    "\n",
    "\n",
    "        - Nombre de la persona predicha, para saber si la predicción es correcta.\n",
    "        - Porcentaje asignado de frames sobre el total del audio, para saber si asigna la mayoría a la persona predicha.\n",
    "        - Desvío de frames asignados a la primera y segunda persona, para saber que tan confiable es la predicción.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        total_frames_audio = len(predictions)\n",
    "\n",
    "        #Total de frames predichos para una persona\n",
    "        total_predictions = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "        for pred in predictions:\n",
    "            total_predictions[pred.argmax()]+=1\n",
    "\n",
    "\n",
    "        #Creación del df con las predicciones en frames por persona\n",
    "        df = pd.DataFrame({\"nombres_personas\": names, \"predicciones\": total_predictions}\n",
    "                         ).sort_values(\"predicciones\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        #Persona predicha\n",
    "        persona_predicha = df['nombres_personas'][0]\n",
    "\n",
    "        #Frames persona predicha\n",
    "        frames_persona_predicha = df['predicciones'][0]\n",
    "\n",
    "        #Porcentaje de frames predichos sobre el total del audio\n",
    "        porcentaje_frames_persona_predicha_sobre_total = (frames_persona_predicha/total_frames_audio)*100\n",
    "\n",
    "        #Desvio de asignación de frames entre la persona a la que más frames le asigna y la segunda.\n",
    "        #Utilizado para saber qué tan seguro se está de la predicción.\n",
    "        desvio_frames_primer_y_segunda_persona = (frames_persona_predicha/df['predicciones'][1])-1\n",
    "\n",
    "\n",
    "        return persona_predicha, porcentaje_frames_persona_predicha_sobre_total, desvio_frames_primer_y_segunda_persona, df\n",
    "        \n",
    "        \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################      \n",
    "     \n",
    "        \n",
    "    def validar_prediccion(porcentaje_sobre_total_audio, desvio_frames_persona_predicha_y_segunda):\n",
    "        \"\"\"\n",
    "            Función que recibe el porcentaje de frames asignados a la persona predicha sobre el total del audio, y\n",
    "            el porcentaje de desvio de asignacion de frames entre la persona predicha y la segunda con más frames asignados.\n",
    "\n",
    "            Devuelve si la predicción es confiable.\n",
    "\n",
    "            La predicción es confiable, si el total de frames asignado es mayor al 40% del audio y si hay una diferencia de un 50% entre\n",
    "            la persona predicha y la segunda.\n",
    "        \"\"\"\n",
    "\n",
    "        validacion_desvio = (1 if desvio_frames_persona_predicha_y_segunda>=.5 else \n",
    "                             (.5 if desvio_frames_persona_predicha_y_segunda>=.25 else 0))\n",
    "        validacion_porcentaje = (1 if np.ceil(porcentaje_sobre_total_audio)>=40 else 0)\n",
    "\n",
    "        return min(validacion_desvio, validacion_porcentaje)\n",
    "    \n",
    "        \n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################\n",
    "    ##############################################################################################################################      \n",
    "               \n",
    "\n",
    "    def score(payload):\n",
    "        \"\"\"\n",
    "            Predict and validate prediction\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "        try:\n",
    "        \n",
    "            #Obtener el nombre del audio de la API call, y su blob.\n",
    "            \n",
    "            audio_to_predict_name = payload['input_data'][0]['values']\n",
    "            \n",
    "            blob_audio, bucket = get_blob_to_predict_and_bucket(audio_to_predict_name)\n",
    "\n",
    "            \n",
    "            \n",
    "            #Cargar el modelo del usuario \n",
    "            \n",
    "            user_expected = blob_audio.name.split('/')[1].upper() \n",
    "            \n",
    "            model = load_model_from_user(user_expected, ibm_cos_client)\n",
    "                        \n",
    "            \n",
    "            \n",
    "            #Carga del archivo del audio y procesado para extracción de MFCC\n",
    "            file = open('temp_audio.wav', 'wb+')\n",
    "            bucket.get_blob(blob_audio.name).download_to_file(file)\n",
    "            file.close()\n",
    "\n",
    "            mfcc = load_MFCC_archivo(file.name)\n",
    "\n",
    "            \n",
    "            \n",
    "            #Predicción sobre los MFCC\n",
    "            predictions = make_predictions(model, mfcc)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Obtención de los nombres de las personas con las que se entrenó el modelo           \n",
    "            nombres_personas = load_names_of_trained_model_from_user(user_expected, ibm_cos_client)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Obtención de los features para validar la predicción\n",
    "            predicted_person, porcentaje_frames_sobre_total_audio, desvio_asignacion_frames, df = prepare_features_to_validate_prediction(predictions, nombres_personas)\n",
    "\n",
    "            \n",
    "            #Validación de la predicción\n",
    "            validacion = validar_prediccion(porcentaje_frames_sobre_total_audio, desvio_asignacion_frames)\n",
    "            \n",
    "            \n",
    "            #Procesado de la validación\n",
    "            return_message = \"\"\n",
    "\n",
    "            \n",
    "            if validacion==1:\n",
    "                \n",
    "                if user_expected!=predicted_person:\n",
    "                    return_message = \"Validación incorrecta para \"+user_expected.replace(\".\", \" \")+\". Se predijo que su nombre es \"+predicted_person+\". Usted es un impostor!!!\"\n",
    "                    \n",
    "                else:    \n",
    "                    return_message = \"Validación correcta para \"+user_expected.replace(\".\", \" \")+\"!!!\"\n",
    "\n",
    "            elif ((validacion > 0) and (user_expected==predicted_person)) or ((validacion==0) and (user_expected==predicted_person)):\n",
    "                return_message = \"Validación dudosa para \"+user_expected.replace(\".\", \" \")+\". Por favor, repita la prueba!!!\"\n",
    "\n",
    "            else:\n",
    "                return_message = \"Validación incorrecta para \"+user_expected.replace(\".\", \" \")+\". Usted es un impostor!!!\"\n",
    "                \n",
    "\n",
    "            \n",
    "            return {'predictions': [{'values': return_message}]}\n",
    "            \n",
    "        \n",
    "        \n",
    "        except Exception as e:\n",
    "            return {'predictions': [{'values': \"Error when trying to make a prediction for the audio\"+audio_to_predict_name+\". Please check the logs and try in a few moments!\"}]}\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comenzamos configuración para deploy y deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seteamos el cliente y el espacio al que deployamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos el cliente de ML\n",
    "\n",
    "wml_client = APIClient(wml_credentials)\n",
    "\n",
    "wml_client.spaces.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guardamos el ID del espacio donde se desplegará el modelo y lo seteamos como default\n",
    "\n",
    "SPACE_ID = \"SPACE_ID_TO_DEPLOY_FROM_wml_client.spaces.list()\"\n",
    "\n",
    "wml_client.set.default_space(SPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuramos el entorno al que deployamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
      "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
      "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
      "spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\n",
      "tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\n",
      "spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "wml_client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el yaml con las librerias necesarias extras, seteamos el software spec base, y agregamos las librerias del yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yml =\\\n",
    "\"\"\"name: python38\n",
    "channels:\n",
    "  - conda-forge    \n",
    "  - nodefaults\n",
    "dependencies:\n",
    "  - librosa\n",
    "  - pip:\n",
    "    - google-cloud-storage\n",
    "\n",
    "prefix: /opt/anaconda3/envs/python38\n",
    "\"\"\"\n",
    "\n",
    "with open(\"config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_sw_spec_uid = wml_client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "base_sw_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: python38\r\n",
      "channels:\r\n",
      "  - conda-forge    \r\n",
      "  - nodefaults\r\n",
      "dependencies:\r\n",
      "  - librosa\r\n",
      "  - pip:\r\n",
      "    - google-cloud-storage\r\n",
      "\r\n",
      "prefix: /opt/anaconda3/envs/python38\r\n"
     ]
    }
   ],
   "source": [
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el YAML tiene el detalle de librerías adicionales como un package. Ahora desplegamos el package para poder usarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating package extensions\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "meta_prop_pkg_extn = {\n",
    "    wml_client.package_extensions.ConfigurationMetaNames.NAME: \"Librosa XXS env (deploy)\",\n",
    "    wml_client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Environment with Librosa and libraries to make predictions\",\n",
    "    wml_client.package_extensions.ConfigurationMetaNames.TYPE: \"conda_yml\"\n",
    "}\n",
    "\n",
    "pkg_extn_details = wml_client.package_extensions.store(meta_props=meta_prop_pkg_extn, file_path=\"config.yaml\")\n",
    "pkg_extn_uid = wml_client.package_extensions.get_uid(pkg_extn_details)\n",
    "pkg_extn_url = wml_client.package_extensions.get_href(pkg_extn_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desplegamos el software SPEC sobre el que se ejecutará la función y agregamos el package con las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_prop_sw_spec = {\n",
    "    wml_client.software_specifications.ConfigurationMetaNames.NAME: \"Librosa XXS (deploy) software_spec\",\n",
    "    wml_client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\"guid\": base_sw_spec_uid}\n",
    "}\n",
    "\n",
    "sw_spec_details = wml_client.software_specifications.store(meta_props=meta_prop_sw_spec)\n",
    "sw_spec_uid = wml_client.software_specifications.get_uid(sw_spec_details)\n",
    "\n",
    "wml_client.software_specifications.add_package_extension(sw_spec_uid, pkg_extn_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos la función de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    wml_client.repository.FunctionMetaNames.NAME: \"Make prediction function\",\n",
    "    wml_client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: sw_spec_uid\n",
    "}\n",
    "\n",
    "function_details = wml_client.repository.store_function(meta_props=meta_props, function=deployable_callable)\n",
    "function_uid = wml_client.repository.get_function_uid(function_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'software_spec': {'id': '4ea98c00-d77d-4bef-852c-d6e44f7e9791',\n",
       "   'name': 'Librosa XXS (deploy) software_spec'},\n",
       "  'type': 'python'},\n",
       " 'metadata': {'created_at': '2022-10-25T00:27:22.770Z',\n",
       "  'id': '81882741-f015-4ed2-be37-ec07d104d9a2',\n",
       "  'modified_at': '2022-10-25T00:27:25.093Z',\n",
       "  'name': 'Make prediction function',\n",
       "  'owner': 'IBMid-6650007T1K',\n",
       "  'space_id': '8a50bf52-17ff-401d-a128-7502ce8436f4'},\n",
       " 'system': {'warnings': []}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_client.repository.get_details(function_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ------------------------  ------------------------  ------\n",
      "GUID                                  NAME                      CREATED                   TYPE\n",
      "81882741-f015-4ed2-be37-ec07d104d9a2  Make prediction function  2022-10-25T00:27:22.002Z  python\n",
      "c589d1c3-a54d-42d4-9572-7206ae6b8e4d  Make prediction function  2022-10-24T23:42:43.002Z  python\n",
      "358f33e0-fa8e-40fb-a616-770cd19efb50  Make prediction function  2022-10-21T02:14:23.002Z  python\n",
      "6d2ede50-785f-4bb1-9357-9dcea4226a7d  Train model function      2022-10-15T22:02:17.002Z  python\n",
      "fb5b9ce5-55ca-4392-b21c-d81a49847ab6  Train model function      2022-10-15T22:00:25.002Z  python\n",
      "6d28a0c3-af01-45db-963f-f73e31e54527  Train model function      2022-10-15T21:34:22.002Z  python\n",
      "------------------------------------  ------------------------  ------------------------  ------\n"
     ]
    }
   ],
   "source": [
    "wml_client.repository.list_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desplegamos la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '81882741-f015-4ed2-be37-ec07d104d9a2' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n",
      "............................\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='9d7b9686-4e69-432b-a43f-0a7a8aa097ce'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: \"Deployment of Make prediction function\",\n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "function_deployment = wml_client.deployments.create(function_uid, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  --------------------------------------  -----  ------------------------\n",
      "GUID                                  NAME                                    STATE  CREATED\n",
      "9d7b9686-4e69-432b-a43f-0a7a8aa097ce  Deployment of Make prediction function  ready  2022-10-25T00:27:27.019Z\n",
      "2cf02cf2-3bd6-4dd9-9b72-0a1c2f5cd1fd  Deployment of Make prediction function  ready  2022-10-24T23:42:48.294Z\n",
      "93cfc89d-8bf1-4079-8cca-88e4718f9bff  Deployment of Make prediction function  ready  2022-10-21T02:16:32.909Z\n",
      "b46d225b-7b39-42fb-a219-e6bb74c7464f  Deployment of Train model function      ready  2022-10-15T22:02:23.437Z\n",
      "------------------------------------  --------------------------------------  -----  ------------------------\n"
     ]
    }
   ],
   "source": [
    "wml_client.deployments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9d7b9686-4e69-432b-a43f-0a7a8aa097ce'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_id = wml_client.deployments.get_uid(function_deployment)\n",
    "\n",
    "deployment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo de la función desplegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload = {\n",
    "    \"input_data\": [{\n",
    "        'values': \"audios/Gian.grillo/1666222906813.MPEG4\"\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación correcta para GIAN GRILLO!!!\n",
      "CPU times: user 6.75 ms, sys: 7.36 ms, total: 14.1 ms\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = wml_client.deployments.score(deployment_id, scoring_payload)\n",
    "print(predictions[\"predictions\"][0][\"values\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
